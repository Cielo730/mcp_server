from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_openai import ChatOpenAI
from langchain.agents import create_agent
from langchain_core.messages import HumanMessage
from langchain_core.prompts import ChatPromptTemplate
import asyncio
import sys
import os
from dotenv import load_dotenv

base_path = Path(__file__).parent
env_path = base_path / '.env'
load_dotenv(dotenv_path=env_path)

async def main():
    # åˆå§‹åŒ– MCP å®¢æˆ·ç«¯
    client = MultiServerMCPClient(
        {
            "tools_server": {
                "transport": "stdio",
                "command": sys.executable, 
                "args": [os.getenv('mcp_args')],
            },
        }
    )

    print("ğŸ”Œ æ­£åœ¨è¿æ¥ MCP æœåŠ¡å™¨...")
    try:
        # è·å–å·¥å…· è‡ªåŠ¨å¯åŠ¨å­è¿›ç¨‹å¹¶ä¿æŒè¿æ¥
        tools = await client.get_tools()
        print(f"æˆåŠŸåŠ è½½å·¥å…·: {[t.name for t in tools]}")

        llm = ChatOpenAI(
            model=os.getenv('qwen_model_name'),
            temperature=0,
            api_key=os.getenv('qwen_api_key'), 
            base_url=os.getenv('qwen_base_url')
        )

        # prompt = ChatPromptTemplate.from_messages([
        #     ("system", "é‡åˆ°ä»»ä½•é—®é¢˜å¿…é¡»å…ˆè°ƒç”¨å·¥å…·æ¥è·å–ç»“æœï¼Œå¦‚æœæ²¡æœ‰åˆé€‚çš„å·¥å…·åˆ™è‡ªå·±è§£å†³ã€‚"),
        #     ("user", "{input}"),
        #     ("placeholder", "{agent_scratchpad}"),
        # ])

        # åˆ›å»º Agentï¼Œcheckpointer=None è¡¨ç¤ºä¸æŒä¹…åŒ–è®°å¿†ï¼Œä»…æœ¬æ¬¡è¿è¡Œæœ‰æ•ˆ
        agent = create_agent(llm, tools)

        print("Agent æ­£åœ¨æ€è€ƒ...")
        
        # response = await agent.ainvoke(
        #     {"messages": [("user", "å—äº¬æœªæ¥ä¸‰å¤©çš„å¤©æ°”æ€ä¹ˆæ ·")]}
        # )

        # final_response = response["messages"][-1].content
        # print(f"\næœ€ç»ˆç»“æœ: {final_response}")
        async for event in agent.astream(
            {"messages": [("user", "2026æ˜¥æ™šåˆ†ä¼šåœº")]},
            stream_mode="values"
        ):
            message = event["messages"][-1]
            if hasattr(message, "tool_calls") and message.tool_calls:
                for tool_call in message.tool_calls:
                    print(f"æ­£åœ¨è°ƒç”¨å·¥å…·: {tool_call['name']}")
                    # print(f" [å‚æ•°]: {tool_call['args']}")
            # elif message.type == "tool":
            #     content_preview = message.content[:100] + "..." if len(message.content) > 100 else message.content
            #     print(f"[å·¥å…·è¿”å›ç»“æœ]: {content_preview}")
            # elif message.type == "ai" and not message.tool_calls:
            #     pass
        if message.type == "ai":
             print(f"ç»“æœå¦‚ä¸‹:\n{message.content}")

    except Exception as e:
        print(f"è¿è¡Œå‡ºé”™: {e}")
    

if __name__ == "__main__":
    if sys.platform.startswith('win'):
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    asyncio.run(main())